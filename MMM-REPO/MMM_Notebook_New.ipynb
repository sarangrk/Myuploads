{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMM Channel Attribution script\n",
    "\n",
    "Importing all the required libraries for the code implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import operator\n",
    "import sys \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the input files should start with __ABT_(channel_name).xlsx__ for example __ABT_newspaper.xlsx__.<br>\n",
    "\n",
    "Input files should be placed along with this jupyter notebook in same folder. Irrespective of the number of channels i.e. we can have any number of input files for processing.\n",
    "\n",
    "below code will extract all the files starting with ABT_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sk186089/Desktop/MMM/ABT_fb.xlsx\n",
      "/Users/sk186089/Desktop/MMM/ABT_radio.xlsx\n",
      "/Users/sk186089/Desktop/MMM/ABT_newspaper.xlsx\n",
      "/Users/sk186089/Desktop/MMM/ABT_TV.xlsx\n",
      "/Users/sk186089/Desktop/MMM/ABT_twitter.xlsx\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "path = os.getcwd()\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if 'ABT_' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "for f in files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define 5 functions which is 5 different machine learning models. Each and every input file will iterate through these 5 models, and model with highest accuracy will be chosen for final predictions. In remaining 2 function one is for iteration of files and another one is for selection of best model. Functions are as follow<br>\n",
    "1. logistic_regression\n",
    "2. support_vector\n",
    "3. random_forrest\n",
    "4. xgboost\n",
    "5. random_search\n",
    "6. selecting_best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logisctic Regression Model, very basic classification Model.<br> \n",
    "\n",
    "Following are the steps performed:\n",
    "- Feature Scaling\n",
    "- Model Fitting \n",
    "- Prediction \n",
    "- Model Accuracy\n",
    "\n",
    "Function returns AUC value(a performance parameter along with it's model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Feature Scaling\n",
    "    # Importing Library required for feature scalling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Fitting Logistic Regression to the Training set\n",
    "    # Importing library for Logistic Regression Model\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier = LogisticRegression(random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    import sklearn.metrics as metrics\n",
    "    probs = classifier.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    return metrics.auc(fpr, tpr), classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine, classification Model.<br> \n",
    "\n",
    "Following are the steps performed:\n",
    "- Feature Scaling\n",
    "- Model Fitting \n",
    "- Prediction \n",
    "- Model Accuracy\n",
    "\n",
    "Function returns AUC value(a performance parameter along with it's model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector(X_train, X_test, y_train, y_test):  \n",
    "    \n",
    "    # Feature Scaling\n",
    "    # Importing Library required for feature scalling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    # Fitting Support Vector to the Training set\n",
    "    # Importing library for Support Vector Model\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0, probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    import sklearn.metrics as metrics\n",
    "    probs = classifier.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    return metrics.auc(fpr, tpr), classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forrest, an ensamle Technique classification Model.<br> \n",
    "\n",
    "Following are the steps performed:\n",
    "- Feature Scaling\n",
    "- Model Fitting \n",
    "- Prediction \n",
    "- Model Accuracy\n",
    "\n",
    "Function returns AUC value(a performance parameter along with it's model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forrest(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Feature Scaling\n",
    "    # Importing Library required for feature scalling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    # Fitting Random Forrest to the Training set\n",
    "    # Importing library for Random Forrest Model\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    import sklearn.metrics as metrics\n",
    "    probs = classifier.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    return metrics.auc(fpr, tpr), classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting, an ensamle Technique classification Model.<br> \n",
    "\n",
    "Following are the steps performed:\n",
    "- Feature Scaling\n",
    "- Model Fitting \n",
    "- Prediction \n",
    "- Model Accuracy\n",
    "\n",
    "Function returns AUC value(a performance parameter along with it's model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Feature Scaling\n",
    "    # Importing Library required for feature scalling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    # Fitting XGBoost to the Training set\n",
    "    # Importing library for XGBoost Model\n",
    "    from xgboost import XGBClassifier\n",
    "    classifier = XGBClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    import sklearn.metrics as metrics\n",
    "    probs = classifier.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    return metrics.auc(fpr, tpr), classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cross Validation, Grid Search and Parameter Tunning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting, an ensamle Technique classification Model.<br> \n",
    "\n",
    "Following are the steps performed:\n",
    "- Feature Scaling\n",
    "- Model Parameter selection inputs \n",
    "- Model Fitting \n",
    "- Prediction \n",
    "- Model Accuracy\n",
    "\n",
    "Function returns AUC value(a performance parameter along with it's model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # Number of Folds\n",
    "    fold = 5\n",
    "    paramCombinations = 10\n",
    "    skf = StratifiedKFold(random_state=42,shuffle=True,n_splits=fold)\n",
    "    param_RF = {\n",
    "                'n_estimators' : [10,50,100,150,200],\n",
    "                'max_depth'    : [3, 4, 5, 8, 10, 12]\n",
    "                }\n",
    "\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    rand_search = RandomizedSearchCV(rf,\n",
    "                                     param_distributions=param_RF,\n",
    "                                     #verbose= 3, #Uncomment if you want to see details of execution\n",
    "                                     scoring= 'roc_auc',\n",
    "                                     random_state=42,\n",
    "                                     n_iter=paramCombinations, \n",
    "                                     cv = skf.split(X_cv,y_cv))\n",
    "\n",
    "    rand_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = rand_search.predict(X_test)\n",
    "    \n",
    "    # Making the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    import sklearn.metrics as metrics\n",
    "    probs = rand_search.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    return metrics.auc(fpr, tpr), rand_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing and Selecting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function created to select the best performing model and create a scoring dataset using that model so as to genrate output which will be used for Markov Chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting_best_model(roc_auc_LR, roc_auc_RF, roc_auc_SVM, roc_auc_XGB, roc_auc_RS, classifier_LR, classifier_SVM, classifier_RF, classifier_XGB, rand_search, channel):\n",
    "    \n",
    "    # Creating Dictionary in which Key will be Model Synonym and Value will be AUC number.\n",
    "    AUC_DICT = {'LR':roc_auc_LR, \n",
    "                'RF':roc_auc_RF, \n",
    "                'SVM':roc_auc_SVM,\n",
    "                'XGB':roc_auc_XGB,\n",
    "                'RS':roc_auc_RS}\n",
    "\n",
    "    # Creating Dictionary in which Key will be Model Synonym and Value will be Models.\n",
    "    classifier_DICT = {'LR':classifier_LR,\n",
    "                       'SVM':classifier_SVM,\n",
    "                       'RF':classifier_RF,\n",
    "                       'XGB':classifier_XGB,\n",
    "                       'RS':rand_search}\n",
    "    \n",
    "    # Slecting key with Maximum AUC value i.e the mode with highest accuracy\n",
    "    max_auc = max(AUC_DICT.items(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "    \n",
    "    # Scoring entire table with Model selected above X_final is the entire dataset.\n",
    "    probs_f = classifier_DICT[max_auc].predict_proba(X_final)\n",
    "    preds_f = probs_f[:,1]\n",
    "    prob    = pd.DataFrame(preds_f)\n",
    "    df['Probablity'] = prob\n",
    "    \n",
    "    # To calculate lift we are considering all the records with Application Flag as '1'\n",
    "    df_lift = df.iloc[:,[0,-2,-1]][df['app_flg'] == 1]\n",
    "    # Sorting entire filtered dataset on Probablity in ascending order\n",
    "    df_lift = df_lift.sort_values(by='Probablity',ascending=False)\n",
    "    # Genrating a row id column which will help us to create groups of rows\n",
    "    df_lift['row_id'] = range(0,0+len(df_lift))\n",
    "    # Bucketing entire data set 10% of rows i.e deciles\n",
    "    df_lift['decile'] = (df_lift['row_id']/(len(df_lift)/10)).astype(int)\n",
    "    # Taking average probablity of 2nd decile bucket, which is our cutoff value.\n",
    "    cutoff = df_lift.iloc[:,2][df_lift['decile'] == 2].mean()\n",
    "    # Creating final dataset\n",
    "    df_final = df.iloc[:,[0,-1]][df['app_flg'] == 1]\n",
    "    \n",
    "    # A small function created so that if probability is more than cutoff we can replace the same \n",
    "    # with channel name\n",
    "    def f(row):\n",
    "        if row['Probablity'] > cutoff:\n",
    "            val = channel\n",
    "        else:\n",
    "            val = 0\n",
    "        return val\n",
    "    df_final['conversion'] = df_final.apply(f, axis=1)\n",
    "    df_final['channel'] = channel\n",
    "    df_final['cutoff'] = cutoff\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running for all the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take all the available files and loop through functions which we had defined previously. And append to a final dataframe one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel:  fb\n",
      "File Name:  /Users/sk186089/Desktop/MMM/ABT_fb.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk186089/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel:  radio\n",
      "File Name:  /Users/sk186089/Desktop/MMM/ABT_radio.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk186089/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel:  newspaper\n",
      "File Name:  /Users/sk186089/Desktop/MMM/ABT_newspaper.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk186089/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel:  TV\n",
      "File Name:  /Users/sk186089/Desktop/MMM/ABT_TV.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk186089/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel:  twitter\n",
      "File Name:  /Users/sk186089/Desktop/MMM/ABT_twitter.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk186089/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "df_markov = pd.DataFrame()\n",
    "for f in files:\n",
    "    \n",
    "    x = f.find('ABT_')+ 4\n",
    "    y = x - len(f)\n",
    "    channel = f[y:-5]\n",
    "    print('Channel: ',channel)\n",
    "    print('File Name: ',f)\n",
    "    df = pd.read_excel(f)\n",
    "    X  = df.iloc[:,1:-1].values\n",
    "    y  = df.iloc[:,-1].values\n",
    "    \n",
    "    #Splitting entire dataset into Train Test and further splitting it into Cross validation sets.\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "    X_train, X_cv, y_train, y_cv     = train_test_split(X_train, y_train, test_size=0.10, random_state=15)\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_final = sc_X.fit_transform(X)\n",
    "    \n",
    "    # Running all the models iteratively for all the available files.\n",
    "    roc_auc_LR,  classifier_LR  = logistic_regression(X_train, X_test, y_train, y_test)\n",
    "    roc_auc_SVM, classifier_SVM = support_vector(X_train, X_test, y_train, y_test)\n",
    "    roc_auc_RF,  classifier_RF  = random_forrest(X_train, X_test, y_train, y_test)\n",
    "    roc_auc_XGB, classifier_XGB = xgboost(X_train, X_test, y_train, y_test)\n",
    "    roc_auc_RS,  rand_search    = random_search(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_final = selecting_best_model(roc_auc_LR, roc_auc_RF, roc_auc_SVM, roc_auc_XGB, roc_auc_RS, classifier_LR, classifier_SVM, classifier_RF, classifier_XGB, rand_search, channel)\n",
    "    #Creating final dataset for Markov Chain\n",
    "    df_markov = df_markov.append(df_final)\n",
    "    df_markov.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_no</th>\n",
       "      <th>cust_seg</th>\n",
       "      <th>tenure</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>total_rev_Amt</th>\n",
       "      <th>prob_exp_mon1</th>\n",
       "      <th>prob_exp_mon2</th>\n",
       "      <th>prob_exp_mon3</th>\n",
       "      <th>prob_exp_mon4</th>\n",
       "      <th>prob_exp_mon5</th>\n",
       "      <th>prob_exp_mon6</th>\n",
       "      <th>prob_exp_mon7</th>\n",
       "      <th>prob_exp_mon8</th>\n",
       "      <th>prob_exp_mon9</th>\n",
       "      <th>prob_exp_mon10</th>\n",
       "      <th>prob_exp_mon11</th>\n",
       "      <th>prob_exp_mon12</th>\n",
       "      <th>app_flg</th>\n",
       "      <th>Probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8791958</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>4281552</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.962</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8770539</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>4551934</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1040153</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>896681</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2561218</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>3693221</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4973530</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1924669</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_no  cust_seg  tenure  gender  age  total_rev_Amt  prob_exp_mon1  \\\n",
       "0  8791958         1      40       0   50        4281552          0.262   \n",
       "1  8770539         1      56       1   84        4551934          0.542   \n",
       "2  1040153         4      37       1   50         896681          0.234   \n",
       "3  2561218         2      10       0   83        3693221          0.261   \n",
       "4  4973530         3      58       1   35        1924669          0.543   \n",
       "\n",
       "   prob_exp_mon2  prob_exp_mon3  prob_exp_mon4  prob_exp_mon5  prob_exp_mon6  \\\n",
       "0          0.572          0.186          0.920          0.571          0.972   \n",
       "1          0.696          0.522          0.624          0.371          0.590   \n",
       "2          0.682          0.792          0.366          0.043          0.842   \n",
       "3          0.924          0.046          0.026          0.605          0.952   \n",
       "4          0.628          0.681          0.515          0.218          0.805   \n",
       "\n",
       "   prob_exp_mon7  prob_exp_mon8  prob_exp_mon9  prob_exp_mon10  \\\n",
       "0          0.326          0.181          0.779           0.027   \n",
       "1          0.556          0.244          0.841           0.101   \n",
       "2          0.947          0.665          0.317           0.668   \n",
       "3          0.219          0.000          0.056           0.636   \n",
       "4          0.816          0.020          0.046           0.647   \n",
       "\n",
       "   prob_exp_mon11  prob_exp_mon12  app_flg  Probablity  \n",
       "0           0.102           0.962        1    0.496300  \n",
       "1           0.623           0.366        0    0.464562  \n",
       "2           0.981           0.257        0    0.479115  \n",
       "3           0.060           0.753        0    0.492903  \n",
       "4           0.575           0.965        0    0.465116  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset Markov. This dataset, after some preprocessing, will serve as a input for Markov Chain R script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_markov[\"conversion\"]= df_markov[\"conversion\"].replace('fb', \"FB\")\n",
    "df_markov[\"conversion\"]= df_markov[\"conversion\"].replace('radio', \"R\")\n",
    "df_markov[\"conversion\"]= df_markov[\"conversion\"].replace('newspaper', \"NP\")\n",
    "df_markov[\"conversion\"]= df_markov[\"conversion\"].replace('twitter', \"Tw\")\n",
    "\n",
    "df_markov.to_excel('markov.xlsx')\n",
    "df_markov = pd.read_excel('markov.xlsx',usecols = [i for i in range(1,6)])\n",
    "cl = list(df_markov['cust_no'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morkov Chain input file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_list_data(list):\n",
    "    result= ''\n",
    "    for element in list:\n",
    "        result += str(element) + '>'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dictionary for holding Channels and Values\n",
    "d = {}\n",
    "# 'i' is the customer number \n",
    "for i in cl:\n",
    "    temp = df_markov.loc[(df_markov['cust_no'] == i) & (df_markov['conversion'] != 0),[\"cust_no\",'conversion']] \n",
    "    temp = temp.pivot(index='cust_no', columns='conversion',values='conversion')\n",
    "    key = temp.index.values\n",
    "    try:\n",
    "        key = key[0]\n",
    "    except:\n",
    "        pass\n",
    "    values = list(temp.columns.values)\n",
    "    values = concatenate_list_data(values)\n",
    "    try:\n",
    "        d.update({key:values})\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_markov_final = pd.DataFrame(list(d.items()))\n",
    "df_markov_final.columns = ['Cutomer','Path']\n",
    "df_markov_final['Path'] = df_markov_final['Path'].str[:-1]\n",
    "#df_markov_final.to_excel('Final_Markov.xlsx')\n",
    "temp = df_markov_final.Path.value_counts()\n",
    "df_Markov_R_input = temp.to_frame()\n",
    "df_Markov_R_input = df_Markov_R_input.reset_index()\n",
    "df_Markov_R_input.columns = ['Path','Conversion']\n",
    "# Writing file back to csv\n",
    "df_Markov_R_input.to_csv('Final_Path_count.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R script for Markov Chain\n",
    "\n",
    "At this moment we have to execute below R script separately. \n",
    "\n",
    "Input file for the script is same as created in above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"ChannelAttribution\")\n",
    "# library(ChannelAttribution)\n",
    "# \n",
    "# setwd <- setwd('')\n",
    "# df <- read.csv('Final_Path_count.csv')\n",
    "# df <- df[c(1,2)]\n",
    "# df[2]\n",
    "# \n",
    "# M <- markov_model(df, 'Path', var_value = 'Conversion', var_conv = 'Conversion', sep = '>', order=1, out_more = TRUE)\n",
    "# \n",
    "# write.csv(M$result, file = \"Markov - Output - Conversion values.csv\", row.names=FALSE)\n",
    "# write.csv(M$transition_matrix, file = \"Markov - Output - Transition matrix.csv\", row.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scurve Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading __s_curves_All.xlsx__ file. As the data is scattered into different Tabs, we will read each tab in different dataframe and run the Scurve code in a loop which will execute each dataframe seperatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('s_curves_All.xlsx')\n",
    "df1 = pd.read_excel(xls, 'TV')\n",
    "df2 = pd.read_excel(xls, 'FB')\n",
    "df3 = pd.read_excel(xls, 'Tw')\n",
    "df4 = pd.read_excel(xls, 'NP')\n",
    "df5 = pd.read_excel(xls, 'R')\n",
    "datafames = [df1,df2,df3,df4,df5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datafames:\n",
    "    indatafr=i\n",
    "    name = list(indatafr.channel.unique())\n",
    "    name = str(name[0])\n",
    "    indatafr = indatafr.rename(columns=lambda x: x.strip().lower())\n",
    "    indataX = indatafr.loc[:, indatafr.columns != 'app_cnt']\n",
    "    indataY = indatafr.loc[:, indatafr.columns == 'app_cnt']\n",
    "    indataXR=indataX[['spend_0_50k', 'spend_50k_100k', 'spend_100k']]\n",
    "    lm6 = sm.ols(formula='indataY ~ indataXR', data=indatafr).fit()\n",
    "    \n",
    "    # Taking Parameter part of Scurve model lm6\n",
    "    a = lm6.params.values\n",
    "    \n",
    "    # To swap the larger value with smaller one\n",
    "    for i in range(1,len(a)-1):\n",
    "        if a[i+1] > a[i]:\n",
    "            pass\n",
    "        else:\n",
    "            a[i+1] = a[i] \n",
    "    df_final = pd.DataFrame(a[1:4])\n",
    "    spend = [50000,100000,150000]\n",
    "    df_final['spend'] = spend\n",
    "    df_final.columns = [name,'Spend']\n",
    "    df_final = df_final[['Spend',name]]\n",
    "    # Writting File back to scv this file will be further used in Scurve graph creation.\n",
    "    df_final.to_excel('Scurve_Output_'+name+'.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
